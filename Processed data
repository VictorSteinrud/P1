import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
import os

data = pd.read_csv(r"C:\Users\Victor Steinrud\Downloads\fraudTrain.csv")

data = data.drop(["trans_date_trans_time", "first", "last", "street", "trans_num", "unix_time", "merchant", "cc_num", 'job', 'state', 'gender'], axis=1)

cat_encoder = OneHotEncoder()

#job 1hot
def read_txt_to_list(filename):
    with open(filename, 'r') as file:     
        return [line.strip() for line in file.read().split(';')]

os.chdir(r"C:\Users\Victor Steinrud\Documents\DAKI\P1\Feature-valg\jobgroups")
txt_files = [file for file in os.listdir() if file.endswith('.txt')]
txt_data = {}
for file in txt_files:
    txt_data[file.replace('.txt', '')] = read_txt_to_list(file)

for index, row in data.iterrows():
    for category, values in txt_data.items():
        if row['job'] in values:  
            data.at[index, 'job'] = category
            break

job_cat = data[['job']]
job_cat_1hot = cat_encoder.fit_transform(job_cat)
job_cat_1hot_array = job_cat_1hot.toarray()






#category 1hot
Purchase_category = data[["category"]]
purchase_cat_1hot = cat_encoder.fit_transform(Purchase_category)
purchase_cat_1hot_array = purchase_cat_1hot.toarray()




#dob 1hot
data['dob'] = data['dob'].str[2].map({
    '0': '1900s',
    '1': '1910s',
    '2': '1920s',
    '3': '1930s',
    '4': '1940s',
    '5': '1950s',
    '6': '1960s',
    '7': '1970s',
    '8': '1980s',
    '9': '1990s'
})

dob = data[["dob"]]
dob_1hot = cat_encoder.fit_transform(dob)
dob_1hot_array = dob_1hot.toarray()


#state 1hot
state = data[["state"]]
state_1hot = cat_encoder.fit_transform(state)
state_1hot_array = state_1hot.toarray()





#features der skal minmax scales er: 
    #amt, lat, long, city_pop, merch_lat, merch_long, 
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

std_scaler = MinMaxScaler()

#standardiseret amt
amt_values = data['amt']
amt_array = amt_values.values.reshape(-1, 1)
amt_std_scaled = std_scaler.fit_transform(amt_array)

#standardiseret lat
lat_values = data['lat']
lat_array = lat_values.values.reshape(-1, 1)
lat_std_scaled = std_scaler.fit_transform(lat_array)

#standardiseret long
long_values = data['long']
long_array = long_values.values.reshape(-1, 1)
long_std_scaled = std_scaler.fit_transform(long_array)

#standardiseret citypop
citypop_values = data['city_pop']
citypop_array = citypop_values.values.reshape(-1, 1)
citypop_std_scaled = std_scaler.fit_transform(citypop_array)

#standardiseret merch_lat
mlat_values = data['merch_lat']
mlat_array = mlat_values.values.reshape(-1, 1)
mlat_std_scaled = std_scaler.fit_transform(mlat_array)

#standardiseret merch_long
mlong_values = data['merch_long']
mlong_array = mlong_values.values.reshape(-1, 1)
mlong_std_scaled = std_scaler.fit_transform(mlong_array)

